{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1GvQY_BnAHJu2ucA3Dn0fFhWaqPejgRh5","authorship_tag":"ABX9TyOcIR05rpD49zxOb0fW0DC4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"490idIZLcjpF","executionInfo":{"status":"ok","timestamp":1727586543106,"user_tz":-420,"elapsed":64854,"user":{"displayName":"Adri Hasfi","userId":"18224241730414646297"}},"outputId":"49e6c000-10ed-452b-cc1f-6e5469e29c61"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uZ8ILjkWcQV9","executionInfo":{"status":"ok","timestamp":1727586738318,"user_tz":-420,"elapsed":11824,"user":{"displayName":"Adri Hasfi","userId":"18224241730414646297"}},"outputId":"54ec4357-9e31-4920-ad20-e44a92b0f0be"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting snscrape\n","  Downloading snscrape-0.7.0.20230622-py3-none-any.whl.metadata (4.9 kB)\n","Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from snscrape) (2.32.3)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from snscrape) (4.9.4)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from snscrape) (4.12.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from snscrape) (3.16.1)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->snscrape) (2.6)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->snscrape) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->snscrape) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->snscrape) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->snscrape) (2024.8.30)\n","Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->snscrape) (1.7.1)\n","Downloading snscrape-0.7.0.20230622-py3-none-any.whl (74 kB)\n","\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/74.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.8/74.8 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: snscrape\n","Successfully installed snscrape-0.7.0.20230622\n","Collecting ntscraper\n","  Downloading ntscraper-0.3.17-py3-none-any.whl.metadata (7.4 kB)\n","Requirement already satisfied: requests>=2.28 in /usr/local/lib/python3.10/dist-packages (from ntscraper) (2.32.3)\n","Requirement already satisfied: beautifulsoup4>=4.11 in /usr/local/lib/python3.10/dist-packages (from ntscraper) (4.12.3)\n","Requirement already satisfied: lxml>=4.9 in /usr/local/lib/python3.10/dist-packages (from ntscraper) (4.9.4)\n","Requirement already satisfied: tqdm>=4.66 in /usr/local/lib/python3.10/dist-packages (from ntscraper) (4.66.5)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4>=4.11->ntscraper) (2.6)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28->ntscraper) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28->ntscraper) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28->ntscraper) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28->ntscraper) (2024.8.30)\n","Downloading ntscraper-0.3.17-py3-none-any.whl (12 kB)\n","Installing collected packages: ntscraper\n","Successfully installed ntscraper-0.3.17\n","Requirement already satisfied: tenacity in /usr/local/lib/python3.10/dist-packages (9.0.0)\n"]}],"source":["!pip3 install snscrape\n","!pip install ntscraper\n","!pip install tenacity"]},{"cell_type":"code","source":["#Utility\n","import requests\n","import time\n","import random\n","from datetime import datetime\n","import pytz\n","import itertools\n","import ssl\n","import re\n","from sklearn.feature_extraction.text import CountVectorizer\n","\n","#Scraping Packages\n","# from bs4 import BeautifulSoup\n","# import snscrape.modules.twitter as sntwitter\n","\n","#Dataframe Packages\n","import pandas as pd\n","import numpy as np\n","\n","#Visualization Packages\n","import seaborn as sns\n","\n","#Model Packages\n","import pickle\n","import nltk"],"metadata":{"id":"N4H6NHWAcqFG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Test Scraper instance\n","from ntscraper import Nitter\n","\n","scraper = Nitter(log_level=1, skip_instance_check=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KV8Muf5Uc2Gj","executionInfo":{"status":"ok","timestamp":1727595939789,"user_tz":-420,"elapsed":15060,"user":{"displayName":"Adri Hasfi","userId":"18224241730414646297"}},"outputId":"a492be7c-a896-4acd-a5e3-6fb4c8864638"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Testing instances: 100%|██████████| 16/16 [00:14<00:00,  1.10it/s]\n"]}]},{"cell_type":"code","source":["help(Nitter)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZMVYjFg1hl-Z","executionInfo":{"status":"ok","timestamp":1727586788999,"user_tz":-420,"elapsed":22,"user":{"displayName":"Adri Hasfi","userId":"18224241730414646297"}},"outputId":"08132394-2f86-429d-bad3-49edd933ee3d","collapsed":true},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Help on class Nitter in module ntscraper.nitter:\n","\n","class Nitter(builtins.object)\n"," |  Nitter(instances=None, log_level=1, skip_instance_check=False)\n"," |  \n"," |  Methods defined here:\n"," |  \n"," |  __init__(self, instances=None, log_level=1, skip_instance_check=False)\n"," |      Nitter scraper\n"," |      :param instances: accepts a list of instances or a single instance in this format: \"https://{host}:{port}\", e.g. \"http://localhost:8080\n"," |      :param log_level: logging level\n"," |      :param skip_instance_check: True if the health check of all instances and the instance change during execution should be skipped\n"," |  \n"," |  get_profile_info(self, username, max_retries=5, instance=None, mode='simple')\n"," |      Get profile information for a user or a list of users\n"," |      \n"," |      :param username: username/s of the page to scrape (str or list of str)\n"," |      :param max_retries: max retries to scrape a page. Default is 5\n"," |      :param instance: Nitter instance to use. Default is None\n"," |      :param mode: Mode of fetching profile info. 'simple' for basic info, 'detail' for detailed info including following and followers lists. Default is 'simple'\n"," |      :return: dictionary of the profile's information or list of dictionaries if username is a list. The dictionary contains the following keys:\n"," |          - image: URL of the profile image\n"," |          - name: Full name of the user\n"," |          - username: Username of the user\n"," |          - id: Profile ID\n"," |          - bio: Bio of the user\n"," |          - location: Location of the user\n"," |          - website: Website URL of the user\n"," |          - joined: Date when the user joined\n"," |          - stats: Dictionary containing the following keys:\n"," |              - tweets: Number of tweets\n"," |              - following: Number of users the profile is following\n"," |              - followers: Number of followers\n"," |              - likes: Number of likes\n"," |              - media: Number of media posts\n"," |          - following_list: List of usernames the profile is following (only in 'detail' mode)\n"," |          - followers_list: List of usernames following the profile (only in 'detail' mode)\n"," |  \n"," |  get_random_instance(self)\n"," |      Get a random Nitter instance\n"," |      \n"," |      :return: URL of random Nitter instance\n"," |  \n"," |  get_tweet_by_id(self, username, tweet_id, instance=None, max_retries=5)\n"," |      Fetch a tweet by its ID.\n"," |      \n"," |      :param username: The username of the tweet.\n"," |      :param tweet_id: The ID of the tweet to fetch.\n"," |      :param instance: The specific Nitter instance to use.\n"," |      :param max_retries: Max retries to scrape a page. Default is 5.\n"," |      :return: Dictionary of the tweet content.\n"," |  \n"," |  get_tweets(self, terms, mode='term', number=-1, since=None, until=None, near=None, language=None, to=None, replies=False, filters=None, exclude=None, max_retries=5, instance=None)\n"," |      Scrape the specified term from Nitter\n"," |      \n"," |      :param terms: string/s to search for\n"," |      :param mode: search mode. Default is 'term', can also be 'hashtag' or 'user'\n"," |      :param number: number of tweets to scrape. Default is -1 (to not set a limit).\n"," |      :param since: date to start scraping from, formatted as YYYY-MM-DD. Default is None\n"," |      :param until: date to stop scraping at, formatted as YYYY-MM-DD. Default is None\n"," |      :param near: near location of the tweets. Default is None (anywhere)\n"," |      :param language: language of the tweets. Default is None (any language)\n"," |      :param to: user to which the tweets are directed. Default is None (any user)\n"," |      :param replies: True if both tweets and replies are needed. If 'filters' or 'exclude' are set, this option will be overridden. Default is False\n"," |      :param filters: list of filters to apply. Default is None\n"," |      :param exclude: list of filters to exclude. Default is None\n"," |      :param max_retries: max retries to scrape a page. Default is 5\n"," |      :param instance: Nitter instance to use. Default is None\n"," |      :return: dictionary or array with dictionaries (in case of multiple terms) of the tweets and threads for the provided terms\n"," |  \n"," |  ----------------------------------------------------------------------\n"," |  Data descriptors defined here:\n"," |  \n"," |  __dict__\n"," |      dictionary for instance variables (if defined)\n"," |  \n"," |  __weakref__\n"," |      list of weak references to the object (if defined)\n","\n"]}]},{"cell_type":"code","source":["#filter params\n","search_term = \"tapera\".lower()\n","start_date = \"2024-01-01\"\n","end_date = \"2024-09-20\""],"metadata":{"id":"QXydg3mMc4-U"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["help(scraper.get_tweets)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TQRUXdOIeX3m","executionInfo":{"status":"ok","timestamp":1727586868206,"user_tz":-420,"elapsed":398,"user":{"displayName":"Adri Hasfi","userId":"18224241730414646297"}},"outputId":"39fb58d4-8b17-474b-f075-f10b1ff7e1fb","collapsed":true},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Help on method get_tweets in module ntscraper.nitter:\n","\n","get_tweets(terms, mode='term', number=-1, since=None, until=None, near=None, language=None, to=None, replies=False, filters=None, exclude=None, max_retries=5, instance=None) method of ntscraper.nitter.Nitter instance\n","    Scrape the specified term from Nitter\n","    \n","    :param terms: string/s to search for\n","    :param mode: search mode. Default is 'term', can also be 'hashtag' or 'user'\n","    :param number: number of tweets to scrape. Default is -1 (to not set a limit).\n","    :param since: date to start scraping from, formatted as YYYY-MM-DD. Default is None\n","    :param until: date to stop scraping at, formatted as YYYY-MM-DD. Default is None\n","    :param near: near location of the tweets. Default is None (anywhere)\n","    :param language: language of the tweets. Default is None (any language)\n","    :param to: user to which the tweets are directed. Default is None (any user)\n","    :param replies: True if both tweets and replies are needed. If 'filters' or 'exclude' are set, this option will be overridden. Default is False\n","    :param filters: list of filters to apply. Default is None\n","    :param exclude: list of filters to exclude. Default is None\n","    :param max_retries: max retries to scrape a page. Default is 5\n","    :param instance: Nitter instance to use. Default is None\n","    :return: dictionary or array with dictionaries (in case of multiple terms) of the tweets and threads for the provided terms\n","\n"]}]},{"cell_type":"code","source":["# Scraping Tweet by text\n","ruu_term_tweets = scraper.get_tweets(search_term\n","                                        ,mode = 'term'\n","                                        ,since = start_date\n","                                        ,until = end_date\n","                                        ,language = 'id'\n","                                        # ,instance = 'https://nitter.lucabased.xyz/'\n","                                        )"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QjDQRHApc8GI","executionInfo":{"status":"ok","timestamp":1727596024287,"user_tz":-420,"elapsed":3104,"user":{"displayName":"Adri Hasfi","userId":"18224241730414646297"}},"outputId":"ab6acb4d-a6c1-47e4-8921-f4429af166c8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:root:No instance specified, using random instance https://nitter.privacydev.net\n","WARNING:root:Fetching error: Instance has been rate limited.Use another instance or try again later.\n"]}]},{"cell_type":"code","source":["# Access the list of tweets from the dictionary\n","tweets_list = ruu_term_tweets['tweets']\n","\n","# Create the DataFrame using the list of tweets\n","df_ruu = pd.DataFrame(tweets_list)\n","\n","# Add ruu label\n","df_ruu['ruu'] = 'RUU MD3'\n","\n","# Move 'ruu' column to the first position\n","cols = list(df_ruu.columns)\n","cols.insert(0, cols.pop(cols.index('ruu')))\n","df_ruu = df_ruu.loc[:, cols]"],"metadata":{"id":"OUKfy2fpdATo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_ruu.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":53},"id":"fVPJIjLwNNRG","executionInfo":{"status":"ok","timestamp":1726985915516,"user_tz":-420,"elapsed":5,"user":{"displayName":"Adri Hasfi","userId":"18224241730414646297"}},"outputId":"c2d4f72e-0378-4fb4-c877-65ae885b520b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Empty DataFrame\n","Columns: [ruu]\n","Index: []"],"text/html":["\n","  <div id=\"df-8ff83fdb-897d-4768-8ce4-f029391a1d89\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ruu</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8ff83fdb-897d-4768-8ce4-f029391a1d89')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-8ff83fdb-897d-4768-8ce4-f029391a1d89 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-8ff83fdb-897d-4768-8ce4-f029391a1d89');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df_ruu","repr_error":"Out of range float values are not JSON compliant: nan"}},"metadata":{},"execution_count":91}]},{"cell_type":"code","source":["df_ruu.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1Sf7Capod265","executionInfo":{"status":"ok","timestamp":1726985917903,"user_tz":-420,"elapsed":365,"user":{"displayName":"Adri Hasfi","userId":"18224241730414646297"}},"outputId":"689f032b-bd2f-4f36-fd59-80f8a84fdcbf"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(0, 1)"]},"metadata":{},"execution_count":92}]},{"cell_type":"code","source":["# Save the DataFrame to a CSV file\n","df_ruu.to_csv('/content/drive/MyDrive/Work & Courses/SAS Hackathon/hasil_scrape_ruu/ruu_md3_tweets.csv', index=False)"],"metadata":{"id":"CvWVRhGl8Ozu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_tapera = pd.read_csv('/content/drive/MyDrive/tapera_tweets_sliced.csv')\n","df_tapera.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Wt1kRfX5d_GX","executionInfo":{"status":"ok","timestamp":1726819654868,"user_tz":-420,"elapsed":701,"user":{"displayName":"Adri Hasfi","userId":"18224241730414646297"}},"outputId":"41021ff3-ca3e-4a20-a6a9-b1ce9f195ecd"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(111, 14)"]},"metadata":{},"execution_count":56}]}]}